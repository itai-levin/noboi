{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import re\n",
    "import numpy as np\n",
    "import pdb\n",
    "import pickle\n",
    "from parsing_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "date = today.strftime('%d%b%Y')\n",
    "print ('Date prefix:', date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXISTING_GRAPH_PATH = \"../../../b-o-t/19Sep2022_updated_whole_metabolic_network_labeled.pkl\"\n",
    "RHEA_SDF = \"rhea/rhea.sdf\"\n",
    "RHEA_REACTIONS = \"rhea/rhea-reactions.txt\"\n",
    "CHEBI_NAMES_IDS = \"rhea/chebiId_name.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea = Chem.SDMolSupplier(RHEA_SDF)\n",
    "rhea_smiles = []\n",
    "rhea_names = []\n",
    "chebi_to_smiles = {}\n",
    "for m in rhea:\n",
    "    if m:\n",
    "        smiles = Chem.MolToSmiles(m)\n",
    "        chebi_to_smiles[m.GetProp('ACCESSION')] = smiles\n",
    "        if '*' not in smiles:\n",
    "            rhea_smiles.append(standardize_smiles(smiles))\n",
    "            rhea_names.append(m.GetProp('Rhea_ascii_name'))\n",
    "assert len(rhea_smiles)==len(rhea_names)\n",
    "\n",
    "print (\"{} molecules in rhea\".format(len(rhea_smiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXISTING_GRAPH_PATH:\n",
    "    with open(EXISTING_GRAPH_PATH, 'rb') as f:\n",
    "        g = pickle.load(f)\n",
    "    smiles_in_graph = [standardize_smiles(n) for n in g.nodes if '>' not in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(set(rhea_smiles) - set(rhea_smiles).intersection(set(smiles_in_graph))))\n",
    "# set(rhea_smiles) - set(rhea_smiles).intersection(set(smiles_in_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_smiles_to_name = dict(zip(rhea_smiles, rhea_names))\n",
    "names_not_in_graph = []\n",
    "smiles_not_in_graph = []\n",
    "for s in set(rhea_smiles) - set(rhea_smiles).intersection(set(smiles_in_graph)):\n",
    "    names_not_in_graph.append(clean_name(rhea_smiles_to_name[s]))\n",
    "    smiles_not_in_graph.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Uncomment to save\n",
    "\n",
    "# pd.DataFrame({'name':[\"'\"+x+\"'\" for x in names_not_in_graph],\n",
    "#               'smiles':[\"'\"+x+\"'\" for x in smiles_not_in_graph]}).to_csv('rhea/{}_molecules_from_rhea_cleaned_names.csv'.format(date), header=False, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_reaction_ids = []\n",
    "rhea_string_reactions = []\n",
    "rhea_chebi_reactions = []\n",
    "with open(RHEA_REACTIONS, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if line[:10] == 'DEFINITION':\n",
    "            rhea_string_reactions.append(line[12:].strip())\n",
    "        elif line[:8] == 'EQUATION':\n",
    "            rhea_chebi_reactions.append(line[12:].strip())\n",
    "        elif line[:5] == 'ENTRY':\n",
    "            rhea_reaction_ids.append(line[12:].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rhea_string_reactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_reaction_df = pd.DataFrame({'ID': rhea_reaction_ids,\n",
    "                   'reaction_string': rhea_string_reactions,\n",
    "                   'reaction_chebi': rhea_chebi_reactions})\n",
    "rhea_reaction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_reactions = []\n",
    "for i, rxn in enumerate(rhea_chebi_reactions):\n",
    "    parsed_reactions.append(parse_chebi_reaction(rxn, chebi_to_smiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_reaction_df['reaction_smiles'] = parsed_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_f = make_cofactor_dict(np.array(rhea_reaction_df['reaction_chebi'][:]), 10, 0.9, \"f\")\n",
    "dic_r = make_cofactor_dict(np.array(rhea_reaction_df['reaction_chebi'][:]), 10, 0.9, \"r\")\n",
    "\n",
    "\n",
    "cofs = mergeDict(dic_f, dic_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_reactions_no_cofs = []\n",
    "for i, rxn in enumerate(rhea_chebi_reactions):\n",
    "    parsed_reactions_no_cofs.append(parse_chebi_reaction(rxn, chebi_to_smiles, cof_dict=cofs, remove_cofs=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_reaction_df['reaction_smiles_no_cofs'] = parsed_reactions_no_cofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = rhea_reaction_df.groupby('reaction_smiles_no_cofs').aggregate(lambda x : list(np.unique(x)))\n",
    "grouped_df['reaction_smiles_no_cofs'] = grouped_df.index\n",
    "grouped_df['reaction_smiles'] = grouped_df['reaction_smiles'].map(lambda x: x[0])\n",
    "grouped_df['reaction_chebi'] = grouped_df['reaction_chebi'].map(lambda x : x[0])\n",
    "grouped_df['reaction_string'] = grouped_df['reaction_string'].map(lambda x : x[0])\n",
    "grouped_df.index = range(len(grouped_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df[grouped_df['reaction_smiles'].map(lambda x : '*' not in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_df[grouped_df['reaction_smiles'].map(lambda x : '*' not in x)].to_csv('rhea/{}_rhea_reaction_smiles_no_cofs.csv'.format(date), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check \n",
    "\n",
    "rxn = grouped_df.loc[23474,'reaction_chebi']\n",
    "print (rxn)\n",
    "AllChem.ReactionFromSmarts(parse_chebi_reaction(rxn, chebi_to_smiles, cof_dict=cofs, remove_cofs=True), useSmiles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity  check on cofactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebi_df = pd.read_csv(CHEBI_NAMES_IDS, sep='\\t', header=None)\n",
    "# chebi_to_name = chebi_df[0].to_dict()\n",
    "chebi_df[0] = chebi_df[0].map(lambda x : x.strip())\n",
    "chebi_df[1] = chebi_df[1].map(lambda x : x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebi_to_name_dict = pd.Series(chebi_df[1].values,index=chebi_df[0].values).to_dict()\n",
    "\n",
    "for k in list(cofs.keys()):\n",
    "    try:\n",
    "        cof_L = chebi_to_name_dict[k]\n",
    "        cof_R = [chebi_to_name_dict[r] for r in cofs[k]]\n",
    "        print (\"{} : {}\".format(cof_L, cof_R))\n",
    "    except KeyError:\n",
    "        print (\"Can't convert {}\".format(k))\n",
    "        \n",
    "# for v in list(dic_f.values()) + list(dic_r.values()):\n",
    "#     for entry in v:\n",
    "#         try:\n",
    "#             print (chebi_to_name_dict[entry])\n",
    "#         except KeyError:\n",
    "#             print (\"Can't convert {}\".format(entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'chebi:67210 + 28 chebi:66915 <=> chebi:67212 + 28 chebi:15378 + 28 chebi:58223;chebi:67210 + 28 chebi:66915 = chebi:67212 + 28 chebi:15378 + 28 chebi:58223' == 'hebi:67210 + 28 chebi:66915 = chebi:67212 + 28 chebi:15378 + 28 chebi:58223;chebi:67210 + 28 chebi:66915 => chebi:67212 + 28 chebi:15378 + 28 chebi:58223'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(grouped_df['reaction_chebi'][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Metacyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METACYC_REACTIONS = \"metacyc/atom-mappings-smiles.dat\"\n",
    "METACYC_COMPOUND_LINKS = \"metacyc/compound-links.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacyc_reactions = pd.read_csv(METACYC_REACTIONS, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacyc_smiles = set()\n",
    "\n",
    "for reaction in metacyc_reactions[1].values:\n",
    "    try:\n",
    "        reactants, products = reaction.split('>>')\n",
    "        \n",
    "        mapped_smiles_list = reactants.split('.') + products.split('.')\n",
    "        \n",
    "        for smiles in mapped_smiles_list:\n",
    "            if 'R' not in smiles and ' ' not in smiles:\n",
    "                mol = Chem.MolFromSmiles(smiles)\n",
    "                if mol:\n",
    "                    for a in mol.GetAtoms():\n",
    "                        a.SetAtomMapNum(0)\n",
    "                    unmapped_smiles = Chem.MolToSmiles(mol)\n",
    "                    metacyc_smiles.add(standardize_smiles(unmapped_smiles))\n",
    "            \n",
    "    except ValueError:\n",
    "        print(\"Couldn't parse {}\".format(reaction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(metacyc_smiles)\n",
    "print (len(set(rhea_smiles) - set(smiles_in_graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacyc_not_in_net = metacyc_smiles - set(smiles_in_graph) - set(rhea_smiles)\n",
    "print (len(metacyc_smiles - set(smiles_in_graph) - set(rhea_smiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(METACYC_COMPOUND_LINKS, 'r') as f:\n",
    "    a = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_lines = [l.split('\\t') for l in a]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_name = []\n",
    "for l in split_lines:\n",
    "    smiles_name.append((standardize_smiles(l[2].strip()),l[0].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacyc_name_to_smiles_dict = dict(smiles_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "metacyc_names = []\n",
    "for m in metacyc_not_in_net:\n",
    "    if m in metacyc_name_to_smiles_dict.keys():\n",
    "        metacyc_names.append(clean_name(metacyc_name_to_smiles_dict[m]))\n",
    "    else:\n",
    "        metacyc_names.append(clean_name(m))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count / len(metacyc_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Uncomment to save\n",
    "\n",
    "# pd.DataFrame({'name':[\"'\"+x+\"'\" for x in metacyc_names],\n",
    "#               'smiles':[\"'\"+x+\"'\" for x in metacyc_not_in_net]}).to_csv('metacyc/{}_molecules_from_metacyc_cleaned_names.csv'.format(date), header=False, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacyc_reactions[metacyc_reactions[1].map(lambda x : len(re.findall('\\>\\>', x))) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nongeneric_reactions = metacyc_reactions[metacyc_reactions[1].map(lambda x : ' ' not in x and 'R' not in x and '&' not in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unmap(smiles):\n",
    "    if 'R' in smiles or ' ' in smiles:\n",
    "        return re.sub('\\:[0-9]+','', smiles)\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    if m:\n",
    "        for a in m.GetAtoms():\n",
    "            a.SetAtomMapNum(0)\n",
    "        return Chem.MolToSmiles(m)\n",
    "    else:\n",
    "        return re.sub('\\:[0-9]+','', smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out why the reactions in the metacyc db have more than 1 >> \n",
    "check = nongeneric_reactions[1].map(lambda x : len(np.unique([unmap(m.strip()) for m in x.split('>>')][1:])) ==1)\n",
    "\n",
    "\n",
    "assert len(nongeneric_reactions[check]) == len(nongeneric_reactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_product_reactions = ['>>'.join([standardize_smiles(unmap(m.strip())) for m in r.split('>>')][:2]) for r in nongeneric_reactions[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_product_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nongeneric_reactions['standardized_smiles'] = single_product_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nongeneric_reactions[nongeneric_reactions[0]=='+-BORNEOL-DEHYDROGENASE-RXN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UNCOMMENT TO SAVE\n",
    "\n",
    "# nongeneric_reactions.rename(columns={0:'Metacyc_ID',1:'raw_smiles'}).to_csv('metacyc/{}_metacyc_reaction_smiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
