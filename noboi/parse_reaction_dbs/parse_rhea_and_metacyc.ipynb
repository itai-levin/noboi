{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import re\n",
    "import numpy as np\n",
    "import pdb\n",
    "import pickle\n",
    "import os\n",
    "from parsing_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "date = today.strftime('%d%b%Y')\n",
    "print ('Date prefix:', date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip to [MetaCyc](#Parse-Metacyc-Molecules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Rhea Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXISTING_GRAPH_PATH = \"../../../b-o-t/19Sep2022_updated_whole_metabolic_network_labeled.pkl\"\n",
    "RHEA_SDF = \"rhea/rhea.sdf\"\n",
    "# RHEA_SDF = \"/Users/Itai/Desktop/test_2.sdf\"\n",
    "RHEA_REACTIONS = \"rhea/rhea-reactions.txt\"\n",
    "CHEBI_NAMES_IDS = \"rhea/chebiId_name.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reason the > <GENERIC_COMPOUND> was leading to some issues in the files \n",
    "lines_to_write = []\n",
    "with open(RHEA_SDF,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    after_generic = False\n",
    "    for l in lines:\n",
    "        if '<GENERIC_COMPOUND>' in l:\n",
    "            after_generic=True\n",
    "        elif len(l) and after_generic and (l=='$$$$\\n' or l[0]=='>' or len(l)==0):\n",
    "            after_generic=False\n",
    "        if after_generic:\n",
    "            pass\n",
    "        else:\n",
    "            lines_to_write.append(l)     \n",
    "new_file_name = RHEA_SDF[:-4]+'_removed_generics.sdf'\n",
    "with open(new_file_name, 'w') as f:\n",
    "    f.write(''.join(lines_to_write))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea = Chem.SDMolSupplier(new_file_name,)# strictParsing=False, sanitize=False)\n",
    "rhea_smiles = []\n",
    "rhea_names = []\n",
    "chebi_to_smiles = {}\n",
    "for i, m in enumerate(rhea):\n",
    "    if m:\n",
    "        prev_m = m\n",
    "        smiles = Chem.MolToSmiles(m)\n",
    "        chebi_to_smiles[m.GetProp('ACCESSION')] = smiles\n",
    "        if '*' not in smiles:\n",
    "            rhea_smiles.append(standardize_smiles(smiles))\n",
    "            rhea_names.append(m.GetProp('Rhea_ascii_name'))\n",
    "    else:\n",
    "        print (i)\n",
    "assert len(rhea_smiles)==len(rhea_names)\n",
    "\n",
    "print (\"{} molecules in rhea\".format(len(rhea_smiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXISTING_GRAPH_PATH:\n",
    "    with open(EXISTING_GRAPH_PATH, 'rb') as f:\n",
    "        g = pickle.load(f)\n",
    "    smiles_in_graph = [standardize_smiles(n) for n in g.nodes if '>' not in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(set(rhea_smiles) - set(rhea_smiles).intersection(set(smiles_in_graph))))\n",
    "# set(rhea_smiles) - set(rhea_smiles).intersection(set(smiles_in_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_smiles_to_name = dict(zip(rhea_smiles, rhea_names))\n",
    "names_not_in_graph = []\n",
    "smiles_not_in_graph = []\n",
    "for s in set(rhea_smiles) - set(rhea_smiles).intersection(set(smiles_in_graph)):\n",
    "    names_not_in_graph.append(clean_name(rhea_smiles_to_name[s]))\n",
    "    smiles_not_in_graph.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Uncomment to save\n",
    "\n",
    "# pd.DataFrame({'name':[\"'\"+x+\"'\" for x in names_not_in_graph],\n",
    "#               'smiles':[\"'\"+x+\"'\" for x in smiles_not_in_graph]}).to_csv('rhea/{}_molecules_from_rhea_cleaned_names.csv'.format(date), header=False, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Rhea Reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebis_to_rm = [\n",
    "                'CHEBI:30212', #photon\n",
    "                'CHEBI:10545', #electron\n",
    "               ]\n",
    "patts_ls = []\n",
    "for c in chebis_to_rm:\n",
    "    patts_ls.append('\\+ ([0-9]+ )?{} |([0-9]+ )?{} \\+ |( \\+)? ([0-9]+ )?{}$'.format(c,c,c))\n",
    "\n",
    "rm_patt = re.compile('|'.join(patts_ls))\n",
    "\n",
    "rhea_reaction_ids = []\n",
    "rhea_string_reactions = []\n",
    "rhea_chebi_reactions = []\n",
    "with open(RHEA_REACTIONS, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if line[:10] == 'DEFINITION':\n",
    "            rhea_string_reactions.append(line[12:].strip())\n",
    "        elif line[:8] == 'EQUATION':\n",
    "            reaction = line[12:].strip()\n",
    "            reaction = re.sub(rm_patt, '', reaction)\n",
    "            rhea_chebi_reactions.append(reaction)\n",
    "        elif line[:5] == 'ENTRY':\n",
    "            rhea_reaction_ids.append(line[12:].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile('|'.join(patts_ls))\n",
    "print (re.sub(p, '', 'CHEBI:15377 + CHEBI:30212 = CHEBI:16453'))\n",
    "\n",
    "print (re.sub(p, '', 'CHEBI:15377 + CHEBI:30212 => CHEBI:16453'))\n",
    "\n",
    "print (re.sub(p, '', 'CHEBI:15377 + CHEBI:30213 <=> CHEBI:30212'))\n",
    "\n",
    "print (re.sub(p, '', 'CHEBI:30212 + CHEBI:30213 + CHEBI:302156'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rhea_string_reactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_reaction_df = pd.DataFrame({'ID': rhea_reaction_ids,\n",
    "                   'reaction_string': rhea_string_reactions,\n",
    "                   'reaction_chebi': rhea_chebi_reactions})\n",
    "rhea_reaction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_reactions = []\n",
    "for i, rxn in enumerate(rhea_chebi_reactions):\n",
    "    parsed_reactions.append(parse_chebi_reaction(rxn, chebi_to_smiles))\n",
    "    \n",
    "    if not len(parse_chebi_reaction(rxn, chebi_to_smiles)):\n",
    "        print (rxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_reaction_df['reaction_smiles'] = parsed_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_f = make_cofactor_dict(np.array(rhea_reaction_df['reaction_chebi'][:]), 10, 0.9, \"f\")\n",
    "dic_r = make_cofactor_dict(np.array(rhea_reaction_df['reaction_chebi'][:]), 10, 0.9, \"r\")\n",
    "\n",
    "\n",
    "cofs = mergeDict(dic_f, dic_r)\n",
    "\n",
    "#clean up\n",
    "for r in cofs:\n",
    "    cofs[r] = [p for p in cofs[r] if p not in chebi_to_smiles.keys() or '*' in chebi_to_smiles[p]]\n",
    "cofs = {k:v for k,v in cofs.items() if len(v)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_reactions_no_cofs = []\n",
    "for i, rxn in enumerate(rhea_chebi_reactions):\n",
    "    parsed_reactions_no_cofs.append(parse_chebi_reaction(rxn, chebi_to_smiles, cof_dict=cofs, remove_cofs=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_reaction_df['reaction_smiles_no_cofs'] = parsed_reactions_no_cofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_reaction_df['RHEA_ID'] = rhea_reaction_df['ID'].map(lambda x : int(x.replace('RHEA:','')))\n",
    "rhea_reaction_df = rhea_reaction_df.drop(columns='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_2_uniprot = pd.read_csv('rhea/rhea2uniprot_sprot.tsv', sep='\\t')\n",
    "grouped_rhea_2_uniprot = rhea_2_uniprot.groupby('RHEA_ID')\n",
    "grouped_rhea_2_uniprot = grouped_rhea_2_uniprot.aggregate(lambda x : ','.join(list(np.unique(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_2_uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_uniprot_ids = rhea_2_uniprot['ID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_reaction_df = rhea_reaction_df.merge(grouped_rhea_2_uniprot, how='left', on='RHEA_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_reaction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique([rhea_reaction_df.loc[61808, 'ID']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_reaction_df.groupby('reaction_smiles_no_cofs').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_reaction_df.loc[rhea_reaction_df['ID'].isna(), 'ID'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhea_reaction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = rhea_reaction_df.groupby('reaction_smiles_no_cofs').aggregate(lambda x : list(np.unique(x)))\n",
    "grouped_df['reaction_smiles_no_cofs'] = grouped_df.index\n",
    "grouped_df['reaction_smiles'] = grouped_df['reaction_smiles'].map(lambda x: x[0])\n",
    "grouped_df['reaction_chebi'] = grouped_df['reaction_chebi'].map(lambda x : x[0])\n",
    "grouped_df['reaction_string'] = grouped_df['reaction_string'].map(lambda x : x[0])\n",
    "grouped_df.index = range(len(grouped_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df[grouped_df['reaction_smiles'].map(lambda x : '*' not in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save\n",
    "\n",
    "grouped_df[grouped_df['reaction_smiles'].map(lambda x : '*' not in x)].to_csv('rhea/{}_rhea_reaction_smiles_no_cofs.csv'.format(date), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check \n",
    "\n",
    "rxn = grouped_df.loc[23474,'reaction_chebi']\n",
    "print (rxn)\n",
    "AllChem.ReactionFromSmarts(parse_chebi_reaction(rxn, chebi_to_smiles, cof_dict=cofs, remove_cofs=True), useSmiles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity  check on cofactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebi_df = pd.read_csv(CHEBI_NAMES_IDS, sep='\\t', header=None)\n",
    "# chebi_to_name = chebi_df[0].to_dict()\n",
    "chebi_df[0] = chebi_df[0].map(lambda x : x.strip())\n",
    "chebi_df[1] = chebi_df[1].map(lambda x : x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebi_to_name_dict = pd.Series(chebi_df[1].values,index=chebi_df[0].values).to_dict()\n",
    "\n",
    "for k in list(cofs.keys()):\n",
    "    try:\n",
    "        s_L = chebi_to_smiles[k]\n",
    "        s_R = [chebi_to_smiles[r] for r in cofs[k]]\n",
    "        print (\"{} : {}\".format(s_L, s_R))\n",
    "        cof_L = chebi_to_name_dict[k]\n",
    "        cof_R = [chebi_to_name_dict[r] for r in cofs[k]]\n",
    "        print (\"{} : {}\".format(cof_L, cof_R))\n",
    "    except KeyError:\n",
    "        print (\"Can't convert {}\".format(k))\n",
    "        \n",
    "# for v in list(dic_f.values()) + list(dic_r.values()):\n",
    "#     for entry in v:\n",
    "#         try:\n",
    "#             print (chebi_to_name_dict[entry])\n",
    "#         except KeyError:\n",
    "#             print (\"Can't convert {}\".format(entry))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Metacyc Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METACYC_REACTIONS = \"metacyc/reactions.dat\"\n",
    "METACYC_COMPOUND_LINKS = \"metacyc/compound-links.dat\"\n",
    "METACYC_MOL_FILES = \"../../../molecule_databases/Metacyc_v26.5/data/MetaCyc-MOLfiles/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metacyc_reactions = pd.read_csv(METACYC_REACTIONS, sep='\\t', header=None)\n",
    "with open(METACYC_COMPOUND_LINKS, 'r') as f:\n",
    "    a = f.readlines()\n",
    "\n",
    "split_lines = [l.split('\\t') for l in a]\n",
    "name_smiles = []\n",
    "for l in split_lines:\n",
    "    if len(l) >= 3:\n",
    "        name_smiles.append((l[0].strip().lower(),standardize_smiles(l[2].strip())))\n",
    "        \n",
    "metacyc_name_to_smiles_dict = dict(name_smiles)\n",
    "print (len(metacyc_name_to_smiles_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for molfile in os.listdir(METACYC_MOL_FILES):\n",
    "    molname = molfile.replace('.mol','').lower()\n",
    "    mol = Chem.MolFromMolFile(os.path.join(METACYC_MOL_FILES,molfile))\n",
    "    if mol:\n",
    "        if molname not in metacyc_name_to_smiles_dict.keys():\n",
    "            smiles = standardize_smiles(Chem.MolToSmiles(mol))\n",
    "            metacyc_name_to_smiles_dict[molname] = smiles\n",
    "    else:\n",
    "        print (molname, 'was not included')\n",
    "print (len(metacyc_name_to_smiles_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse MetaCyc Reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Reactions\n",
    "attribute_types = {'UNIQUE-ID':'string',\n",
    "    'EC-NUMBER':'string',\n",
    "   'ENZYMATIC-REACTION':'string',\n",
    "   'GIBBS-0':'float',\n",
    "   'IN-PATHWAY':'list',\n",
    "   'LEFT':'list',\n",
    "   'PHYSIOLOGICALLY-RELEVANT?':'string',\n",
    "   'PREDECESSORS':'list',\n",
    "   'REACTION-BALANCE-STATUS':'string',\n",
    "   'REACTION-DIRECTION':'string',\n",
    "   'RIGHT':'list',\n",
    "   'RXN-LOCATIONS':'list',\n",
    "   'SIGNAL':'list',\n",
    "   'SPONTANEOUS?':'str',\n",
    "   'STD-REDUCTION-POTENTIAL':'float',\n",
    "   'SYNONYMS':'list',\n",
    "   'SYSTEMATIC-NAME':'str'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacyc_dict = {}\n",
    "\n",
    "entry_num = 0\n",
    "metacyc_dict[entry_num] = {}\n",
    "for atr in attribute_types:\n",
    "    if attribute_types[atr]=='list':\n",
    "        metacyc_dict[entry_num][atr]=[]\n",
    "    else:\n",
    "        metacyc_dict[entry_num][atr]=None\n",
    "\n",
    "with open(METACYC_REACTIONS, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if line[0] == '#':\n",
    "            pass\n",
    "        else:\n",
    "            if line[:2] == '//':\n",
    "                entry_num += 1\n",
    "                metacyc_dict[entry_num] = {}\n",
    "                for atr in attribute_types:\n",
    "                    if attribute_types[atr]=='list':\n",
    "                        metacyc_dict[entry_num][atr]=[]\n",
    "                    else:\n",
    "                        metacyc_dict[entry_num][atr]=None\n",
    "            \n",
    "            else:\n",
    "                attribute_patt = re.compile('^[A-Z\\-0-9\\?\\^]+ (?:\\- )')\n",
    "                attribute_match = re.findall(attribute_patt, line)\n",
    "                if len (attribute_match)==0:\n",
    "                    print ('Could not find the attribute in line : {}'.format(line))\n",
    "                else:\n",
    "                    attribute = attribute_match[0][:-3]\n",
    "                    attribute_value = re.sub(attribute_patt,'',line).strip()\n",
    "\n",
    "                    if attribute in attribute_types.keys():\n",
    "                        if attribute_types[attribute] == 'list':\n",
    "                            metacyc_dict[entry_num][attribute].append(attribute_value)\n",
    "                        else:\n",
    "                            metacyc_dict[entry_num][attribute] = attribute_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacyc_raw_df = pd.DataFrame.from_dict(metacyc_dict, orient='index')\n",
    "metacyc_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE=['WATER','PROTON','CARBON-DIOXIDE','OXYGEN-MOLECULE','PPI']\n",
    "IGNORE = [x.lower() for x in IGNORE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = ['light', 'e-']\n",
    "\n",
    "metacyc_raw_df['LEFT'] = metacyc_raw_df['LEFT'].map(lambda x : [y for y in x if y.lower() not in to_remove])\n",
    "metacyc_raw_df['RIGHT'] = metacyc_raw_df['RIGHT'].map(lambda x : [y for y in x if y.lower() not in to_remove])\n",
    "\n",
    "metacyc_raw_df['reaction_str'] = metacyc_raw_df['LEFT'].map(lambda x : ' + '.join(x)) + ' = ' + metacyc_raw_df['RIGHT'].map(lambda x : ' + '.join(x))\n",
    "\n",
    "metacyc_raw_df['reaction_str'] = metacyc_raw_df['reaction_str'].map(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_f = make_cofactor_dict(np.array(metacyc_raw_df['reaction_str'][:]), 10, 0.9, \"f\", ignore=IGNORE)\n",
    "dic_r = make_cofactor_dict(np.array(metacyc_raw_df['reaction_str'][:]), 10, 0.9, \"r\", ignore=IGNORE)\n",
    "\n",
    "\n",
    "cofs = mergeDict(dic_f, dic_r)\n",
    "\n",
    "for r in cofs:\n",
    "    cofs[r] = [p for p in cofs[r] if p not in metacyc_name_to_smiles_dict.keys() or '*' in metacyc_name_to_smiles_dict[p]]\n",
    "cofs = {k:v for k,v in cofs.items() if len(v)}\n",
    "\n",
    "cofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_reactions = []\n",
    "for i, rxn in enumerate(metacyc_raw_df['reaction_str'].values):\n",
    "    parsed_reactions.append(parse_chebi_reaction(rxn, metacyc_name_to_smiles_dict, cof_dict=cofs, remove_cofs=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacyc_raw_df['reaction_smiles'] = parsed_reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacyc_df = metacyc_raw_df[metacyc_raw_df['reaction_smiles'].map(lambda x: len(x) > 0)]\n",
    "print (metacyc_df['REACTION-DIRECTION'].unique())\n",
    "\n",
    "rev_df = metacyc_df[metacyc_df['REACTION-DIRECTION']=='REVERSIBLE']\n",
    "flipped_df = pd.concat([metacyc_df[metacyc_df['REACTION-DIRECTION']=='PHYSIOL-RIGHT-TO-LEFT'], metacyc_df[metacyc_df['REACTION-DIRECTION']=='RIGHT-TO-LEFT']])\n",
    "\n",
    "rev_df.loc[:,'reaction_smiles'] = rev_df['reaction_smiles'].map(lambda x: flip_reaction(x))\n",
    "flipped_df.loc[:,'reaction_smiles'] = flipped_df['reaction_smiles'].map(lambda x: flip_reaction(x))\n",
    "metacyc_df = metacyc_df.drop(index=flipped_df.index)\n",
    "\n",
    "\n",
    "metacyc_df = pd.concat([metacyc_df, rev_df, flipped_df]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment to save \n",
    "metacyc_df.to_csv('metacyc/{}_metacyc_reaction_smiles_no_cofs.csv'.format(date), sep='\\t', index=False)\n",
    "print ('Saved to metacyc/{}_metacyc_reaction_smiles_no_cofs.csv'.format(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metacyc_df[metacyc_df['IN-PATHWAY'].map(lambda x: 'PWY-7040' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacyc_df.loc[8815, 'reaction_smiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
